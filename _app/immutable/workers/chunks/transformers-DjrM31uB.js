var Fe=Object.defineProperty;var Ae=(i,e,t)=>e in i?Fe(i,e,{enumerable:!0,configurable:!0,writable:!0,value:t}):i[e]=t;var N=(i,e,t)=>(Ae(i,typeof e!="symbol"?e+"":e,t),t);import{g as Pe,F as ze,c as K,m as j,a as Ce,b as Se,T as z,t as ve,s as ie,i as Q,d as E,e as de,f as Ee,C as re,h as Le,A as S,j as ue,k as Ie,l as Be,n as Re,o as ae,p as De,q as Oe,r as Y,u as je,v as qe,w as Ne,x as Ve,y as Ge,z as Xe,B as We,D as $e,E as Qe,G as He,H as Ue,I as Ze,J as Je,K as te,L as Ye,M as Ke,N as he,O as et,R as H}from"../EmbeddingAdapterWorker-DzW3S58l.js";import{bM as _s,bL as gs,bK as Ms,b3 as bs,b2 as ws,b1 as ys,b0 as Ts,a$ as xs,eu as ks,f8 as Fs,bf as As,bg as Ps,be as zs,bd as Cs,eI as Ss,cS as vs,cR as Es,cQ as Ls,W as Is,Z as Bs,X as Rs,Y as Ds,V as Os,U as js,et as qs,bo as Ns,bn as Vs,bm as Gs,br as Xs,bq as Ws,bp as $s,f3 as Qs,f2 as Hs,cv as Us,cu as Zs,ct as Js,eM as Ys,bS as Ks,bR as eo,c1 as to,c0 as so,b$ as oo,bT as ao,e_ as no,bU as io,ak as ro,an as lo,al as co,am as uo,aj as ho,ai as fo,eD as po,eo as mo,b_ as _o,bZ as go,ec as Mo,ea as bo,e9 as wo,eb as yo,cj as To,ci as xo,ch as ko,eZ as Fo,eO as Ao,a8 as Po,ab as zo,a9 as Co,aa as So,a7 as vo,a6 as Eo,eA as Lo,dq as Io,dp as Bo,dn as Ro,dt as Do,ds as Oo,dr as jo,df as qo,de as No,dd as Vo,aq as Go,at as Xo,ar as Wo,as as $o,ap as Qo,ao as Ho,ex as Uo,aw as Zo,az as Jo,ax as Yo,ay as Ko,av as ea,au as ta,ey as sa,d3 as oa,d2 as aa,d1 as na,dh as ia,dg as ra,cV as la,cW as ca,cU as da,cX as ua,cT as ha,cY as fa,dw as pa,dv as ma,du as _a,aF as ga,aE as Ma,aC as ba,aD as wa,aB as ya,aA as Ta,eC as xa,dm as ka,dl as Fa,ae as Aa,ah as Pa,af as za,ag as Ca,ad as Sa,ac as va,eF as Ea,aI as La,aJ as Ia,aK as Ba,aH as Ra,aG as Da,eT as Oa,e8 as ja,e7 as qa,e6 as Na,eR as Va,dk as Ga,dj as Xa,di as Wa,c4 as $a,c3 as Qa,c2 as Ha,eH as Ua,cg as Za,cf as Ja,ce as Ya,cd as Ka,cc as en,cb as tn,c7 as sn,c6 as on,c5 as an,ca as nn,c9 as rn,c8 as ln,eS as cn,eV as dn,ez as un,dT as hn,dU as fn,dS as pn,ep as mn,cm as _n,cl as gn,ck as Mn,eN as bn,b9 as wn,b8 as yn,b7 as Tn,dJ as xn,dI as kn,dH as Fn,eX as An,eK as Pn,bl as zn,bj as Cn,bk as Sn,bi as vn,bh as En,eJ as Ln,aS as In,aV as Bn,aT as Rn,aU as Dn,aR as On,aQ as jn,eQ as qn,bc as Nn,bb as Vn,ba as Gn,dG as Xn,dF as Wn,dE as $n,f0 as Qn,em as Hn,e5 as Un,e4 as Zn,e3 as Jn,aN as Yn,aP as Kn,aO as ei,aM as ti,aL as si,ev as oi,cJ as ai,cI as ni,cH as ii,S as ri,cy as li,cx as ci,cw as di,eW as ui,$ as hi,_ as fi,f5 as pi,cB as mi,cA as _i,cz as gi,cM as Mi,cL as bi,cK as wi,cP as yi,cO as Ti,cN as xi,cs as ki,cr as Fi,cq as Ai,Q as Pi,es as zi,f7 as Ci,ei as Si,en as vi,cp as Ei,co as Li,cn as Ii,eU as Bi,d6 as Ri,d5 as Di,d4 as Oi,a2 as ji,a5 as qi,a3 as Ni,a4 as Vi,a1 as Gi,a0 as Xi,eB as Wi,bu as $i,bx as Qi,bv as Hi,bw as Ui,bt as Zi,bs as Ji,eL as Yi,dD as Ki,dC as er,dB as tr,eg as sr,eh as or,ef as ar,ej as nr,ek as ir,bW as rr,bV as lr,bX as cr,e$ as dr,bY as ur,d_ as hr,d$ as fr,e0 as pr,dZ as mr,f4 as _r,aY as gr,a_ as Mr,aZ as br,aX as wr,aW as yr,ew as Tr,dc as xr,db as kr,da as Fr,d9 as Ar,d8 as Pr,d7 as zr,b6 as Cr,b5 as Sr,b4 as vr,eG as Er,c$ as Lr,c_ as Ir,d0 as Br,cZ as Rr,el as Dr,er as Or,e2 as jr,e1 as qr,cE as Nr,cD as Vr,cC as Gr,bQ as Xr,cG as Wr,cF as $r,ee as Qr,eq as Hr,ed as Ur,f6 as Zr,dQ as Jr,dR as Yr,dP as Kr,dO as el,f1 as tl,dM as sl,dN as ol,dL as al,dK as nl,dX as il,dY as rl,dW as ll,dV as cl,bP as dl,bO as ul,bN as hl,eY as fl,bD as pl,bB as ml,bC as _l,bz as gl,by as Ml,bG as bl,bJ as wl,bH as yl,bI as Tl,bF as xl,bE as kl,eP as Fl,eE as Al,bA as Pl,dz as zl,dy as Cl,dA as Sl,dx as vl,fb as El,P as Ll,fe as Il,fg as Bl,fa as Rl,fh as Dl,fc as Ol,fd as jl,f9 as ql,ff as Nl}from"../EmbeddingAdapterWorker-DzW3S58l.js";async function tt(i,e){if(typeof AudioContext>"u")throw Error("Unable to load audio from path/URL since `AudioContext` is not available in your environment. Instead, audio data should be passed directly to the pipeline/processor. For more information and some example code, see https://huggingface.co/docs/transformers.js/guides/node-audio-processing.");const t=await(await Pe(i)).arrayBuffer(),s=new AudioContext({sampleRate:e});typeof e>"u"&&console.warn(`No sampling rate provided, using default of ${s.sampleRate}Hz.`);const a=await s.decodeAudioData(t);let o;if(a.numberOfChannels===2){const n=Math.sqrt(2),r=a.getChannelData(0),l=a.getChannelData(1);o=new Float32Array(r.length);for(let c=0;c<a.length;++c)o[c]=n*(r[c]+l[c])/2}else o=a.getChannelData(0);return o}function fe(i){if(i<1)return new Float64Array;if(i===1)return new Float64Array([1]);const e=i-1,t=Math.PI/e,s=new Float64Array(i);for(let a=0;a<i;++a){const o=2*a-e;s[a]=.5+.5*Math.cos(t*o)}return s}const st={htk:i=>2595*Math.log10(1+i/700),kaldi:i=>1127*Math.log(1+i/700),slaney:(i,e=1e3,t=15,s=27/Math.log(6.4))=>i>=e?t+Math.log(i/e)*s:3*i/200};function ne(i,e="htk"){const t=st[e];if(!t)throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".');return typeof i=="number"?t(i):i.map(s=>t(s))}const ot={htk:i=>700*(10**(i/2595)-1),kaldi:i=>700*(Math.exp(i/1127)-1),slaney:(i,e=1e3,t=15,s=Math.log(6.4)/27)=>i>=t?e*Math.exp(s*(i-t)):200*i/3};function at(i,e="htk"){const t=ot[e];if(!t)throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".');return typeof i=="number"?t(i):i.map(s=>t(s))}function nt(i,e){const t=Float64Array.from({length:e.length-1},(n,r)=>e[r+1]-e[r]),s=Array.from({length:i.length},()=>new Array(e.length));for(let n=0;n<i.length;++n){const r=s[n];for(let l=0;l<e.length;++l)r[l]=e[l]-i[n]}const a=e.length-2,o=Array.from({length:a},()=>new Array(i.length));for(let n=0;n<i.length;++n){const r=s[n];for(let l=0;l<a;++l){const c=-r[l]/t[l],d=r[l+2]/t[l+1];o[l][n]=Math.max(0,Math.min(c,d))}}return o}function pe(i,e,t){const s=(e-i)/(t-1);return Float64Array.from({length:t},(a,o)=>i+s*o)}function U(i,e,t,s,a,o=null,n="htk",r=!1){if(o!==null&&o!=="slaney")throw new Error('norm must be one of null or "slaney"');const l=ne(t,n),c=ne(s,n),d=pe(l,c,e+2);let h=at(d,n),f;if(r){const p=a/(i*2);f=ne(Float64Array.from({length:i},(m,_)=>_*p),n),h=d}else f=pe(0,Math.floor(a/2),i);const u=nt(f,h);if(o!==null&&o==="slaney")for(let p=0;p<e;++p){const m=u[p],_=2/(h[p+2]-h[p]);for(let g=0;g<i;++g)m[g]*=_}return u}function it(i,e,t){const s=new i.constructor(i.length+e+t),a=i.length-1;for(let o=0;o<i.length;++o)s[e+o]=i[o];for(let o=1;o<=e;++o)s[e-o]=i[K(o,a)];for(let o=1;o<=t;++o)s[a+e+o]=i[K(a-o,a)];return s}function Me(i,e,t,s,a){if(t<=0)throw new Error("reference must be greater than zero");if(s<=0)throw new Error("min_value must be greater than zero");t=Math.max(s,t);const o=Math.log10(t);for(let n=0;n<i.length;++n)i[n]=e*Math.log10(Math.max(s,i[n])-o);if(a!==null){if(a<=0)throw new Error("db_range must be greater than zero");const n=j(i)[0]-a;for(let r=0;r<i.length;++r)i[r]=Math.max(i[r],n)}return i}function rt(i,e=1,t=1e-5,s=null){return Me(i,20,e,t,s)}function lt(i,e=1,t=1e-10,s=null){return Me(i,10,e,t,s)}function se(i,e,t,s,{fft_length:a=null,power:o=1,center:n=!0,pad_mode:r="reflect",onesided:l=!0,preemphasis:c=null,mel_filters:d=null,mel_floor:h=1e-10,log_mel:f=null,reference:u=1,min_value:p=1e-10,db_range:m=null,remove_dc_offset:_=null,max_num_frames:g=null,do_pad:M=!0,transpose:b=!1}={}){const w=e.length;if(a===null&&(a=t),t>a)throw Error(`frame_length (${t}) may not be larger than fft_length (${a})`);if(w!==t)throw new Error(`Length of the window (${w}) must equal frame_length (${t})`);if(s<=0)throw new Error("hop_length must be greater than zero");if(n){if(r!=="reflect")throw new Error(`pad_mode="${r}" not implemented yet.`);const P=Math.floor((a-1)/2)+1;i=it(i,P,P)}const y=Math.floor(1+Math.floor((i.length-t)/s)),T=l?Math.floor(a/2)+1:a;let F=y,B=y;g!==null&&(g>y?M&&(B=g):B=F=g);const G=new ze(a),R=new Float64Array(a),X=new Float64Array(G.outputBufferSize),J=new Array(F);for(let P=0;P<F;++P){const C=P*s;for(let x=0;x<t;++x)R[x]=i[C+x];if(_){let x=0;for(let I=0;I<t;++I)x+=R[I];const q=x/t;for(let I=0;I<t;++I)R[I]-=q}if(c!==null){for(let x=t-1;x>=1;--x)R[x]-=c*R[x-1];R[0]*=1-c}for(let x=0;x<e.length;++x)R[x]*=e[x];G.realTransform(X,R);const L=new Array(T);for(let x=0;x<L.length;++x){const q=x<<1;L[x]=X[q]**2+X[q+1]**2}J[P]=L}if(o!==null&&o!==2){const P=2/o;for(let C=0;C<J.length;++C){const L=J[C];for(let x=0;x<L.length;++x)L[x]**=P}}const W=d.length,D=new Float32Array(W*B),ke=b?[B,W]:[W,B];for(let P=0;P<W;++P){const C=d[P];for(let L=0;L<F;++L){const x=J[L];let q=0;for(let I=0;I<T;++I)q+=C[I]*x[I];D[b?L*W+P:P*F+L]=Math.max(h,q)}}if(o!==null&&f!==null){const P=Math.min(D.length,F*W);switch(f){case"log":for(let C=0;C<P;++C)D[C]=Math.log(D[C]);break;case"log10":for(let C=0;C<P;++C)D[C]=Math.log10(D[C]);break;case"dB":if(o===1)rt(D,u,p,m);else if(o===2)lt(D,u,p,m);else throw new Error(`Cannot use log_mel option '${f}' with power ${o}`);break;default:throw new Error(`log_mel must be one of null, 'log', 'log10' or 'dB'. Got '${f}'`)}}return{data:D,dims:ke}}function oe(i,e,{periodic:t=!0,frame_length:s=null,center:a=!0}={}){const o=t?i+1:i;let n;switch(e){case"boxcar":n=new Float64Array(o).fill(1);break;case"hann":case"hann_window":n=fe(o);break;case"povey":n=fe(o).map(r=>Math.pow(r,.85));break;default:throw new Error(`Unknown window type ${e}.`)}if(t&&(n=n.subarray(0,i)),s===null)return n;if(i>s)throw new Error(`Length of the window (${i}) may not be larger than frame_length (${s})`);return n}function ct([i,e,t,s]){return[i-t/2,e-s/2,i+t/2,e+s/2]}function le(i,e=.5,t=null,s=!1){const a=i.logits,o=i.pred_boxes,[n,r,l]=a.dims;if(t!==null&&t.length!==n)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let c=[];for(let d=0;d<n;++d){let h=t!==null?t[d]:null,f={boxes:[],classes:[],scores:[]},u=a[d],p=o[d];for(let m=0;m<r;++m){let _=u[m],g=[],M;if(s){M=_.sigmoid().data;for(let b=0;b<M.length;++b)M[b]>e&&g.push(b)}else{let b=j(_.data)[1];if(b===l-1)continue;g.push(b),M=E(_.data)}for(const b of g){let w=p[m].data;w=ct(w),h!==null&&(w=w.map((y,T)=>y*h[(T+1)%2])),f.boxes.push(w),f.classes.push(b),f.scores.push(M[b])}}c.push(f)}return c}function Z(i,e){var t;if(!(i instanceof Float32Array||i instanceof Float64Array))throw new Error(`${e} expects input to be a Float32Array or a Float64Array, but got ${((t=i==null?void 0:i.constructor)==null?void 0:t.name)??typeof i} instead.If using the feature extractor directly, remember to use \`read_audio(url, sampling_rate)\` to obtain the raw audio data of the file/url.`)}function me(i,e,t=0,s=null){let a=Math.round(i/e)*e;return s!==null&&a>s&&(a=Math.floor(i/e)*e),a<t&&(a=Math.ceil(i/e)*e),a}function _e([i,e],t){return[Math.floor(i/t)*t,Math.floor(e/t)*t]}class V extends re{constructor(e){super(),this.config=e}}class k extends V{constructor(e){super(e),this.image_mean=this.config.image_mean??this.config.mean,this.image_std=this.config.image_std??this.config.std,this.resample=this.config.resample??2,this.do_rescale=this.config.do_rescale??!0,this.rescale_factor=this.config.rescale_factor??1/255,this.do_normalize=this.config.do_normalize,this.do_resize=this.config.do_resize,this.do_thumbnail=this.config.do_thumbnail,this.size=this.config.size,this.size_divisibility=this.config.size_divisibility??this.config.size_divisor,this.do_center_crop=this.config.do_center_crop,this.crop_size=this.config.crop_size,this.do_convert_rgb=this.config.do_convert_rgb??!0,this.do_crop_margin=this.config.do_crop_margin,this.pad_size=this.config.pad_size,this.do_pad=this.config.do_pad,this.do_pad&&!this.pad_size&&this.size&&this.size.width!==void 0&&this.size.height!==void 0&&(this.pad_size=this.size)}async thumbnail(e,t,s=2){const a=e.height,o=e.width,n=t.height,r=t.width;let l=Math.min(a,n),c=Math.min(o,r);return l===a&&c===o?e:(a>o?c=Math.floor(o*l/a):o>a&&(l=Math.floor(a*c/o)),await e.resize(c,l,{resample:s}))}async crop_margin(e,t=200){const s=e.clone().grayscale(),a=Se(s.data)[0],n=j(s.data)[0]-a;if(n===0)return e;const r=t/255;let l=s.width,c=s.height,d=0,h=0;for(let f=0;f<s.height;++f){const u=f*s.width;for(let p=0;p<s.width;++p)(s.data[u+p]-a)/n<r&&(l=Math.min(l,p),c=Math.min(c,f),d=Math.max(d,p),h=Math.max(h,f))}return e=await e.crop([l,c,d,h]),e}pad_image(e,t,s,{mode:a="constant",center:o=!1,constant_values:n=0}={}){const[r,l,c]=t;let d,h;if(typeof s=="number"?(d=s,h=s):(d=s.width,h=s.height),d!==r||h!==l){const f=new Float32Array(d*h*c);if(Array.isArray(n))for(let m=0;m<f.length;++m)f[m]=n[m%c];else n!==0&&f.fill(n);const[u,p]=o?[Math.floor((d-r)/2),Math.floor((h-l)/2)]:[0,0];for(let m=0;m<l;++m){const _=(m+p)*d,g=m*r;for(let M=0;M<r;++M){const b=(_+M+u)*c,w=(g+M)*c;for(let y=0;y<c;++y)f[b+y]=e[w+y]}}if(a==="symmetric"){if(o)throw new Error("`center` padding is not supported when `mode` is set to `symmetric`.");const m=l-1,_=r-1;for(let g=0;g<h;++g){const M=g*d,b=K(g,m)*r;for(let w=0;w<d;++w){if(g<l&&w<r)continue;const y=(M+w)*c,T=(b+K(w,_))*c;for(let F=0;F<c;++F)f[y+F]=e[T+F]}}}e=f,t=[h,d,c]}return[e,t]}rescale(e){for(let t=0;t<e.length;++t)e[t]=this.rescale_factor*e[t]}get_resize_output_image_size(e,t){const[s,a]=e.size;let o,n;if(this.do_thumbnail){const{height:r,width:l}=t;o=Math.min(r,l)}else Number.isInteger(t)?(o=t,n=this.config.max_size??o):t!==void 0&&(o=t.shortest_edge,n=t.longest_edge);if(o!==void 0||n!==void 0){const r=o===void 0?1:Math.max(o/s,o/a),l=s*r,c=a*r,d=n===void 0?1:Math.min(n/l,n/c);let h=Math.floor(Number((l*d).toFixed(2))),f=Math.floor(Number((c*d).toFixed(2)));return this.size_divisibility!==void 0&&([h,f]=_e([h,f],this.size_divisibility)),[h,f]}else if(t!==void 0&&t.width!==void 0&&t.height!==void 0){let r=t.width,l=t.height;if(this.config.keep_aspect_ratio&&this.config.ensure_multiple_of){let c=t.height/a,d=t.width/s;Math.abs(1-d)<Math.abs(1-c)?c=d:d=c,l=me(c*a,this.config.ensure_multiple_of),r=me(d*s,this.config.ensure_multiple_of)}return[r,l]}else{if(this.size_divisibility!==void 0)return _e([s,a],this.size_divisibility);throw new Error(`Could not resize image due to unsupported \`this.size\` option in config: ${JSON.stringify(t)}`)}}async resize(e){const[t,s]=this.get_resize_output_image_size(e,this.size);return await e.resize(t,s,{resample:this.resample})}async preprocess(e,{do_normalize:t=null,do_pad:s=null,do_convert_rgb:a=null,do_convert_grayscale:o=null}={}){this.do_crop_margin&&(e=await this.crop_margin(e));const[n,r]=e.size;if(a??this.do_convert_rgb?e=e.rgb():o&&(e=e.grayscale()),this.do_resize&&(e=await this.resize(e)),this.do_thumbnail&&(e=await this.thumbnail(e,this.size,this.resample)),this.do_center_crop){let u,p;Number.isInteger(this.crop_size)?(u=this.crop_size,p=this.crop_size):(u=this.crop_size.width,p=this.crop_size.height),e=await e.center_crop(u,p)}const l=[e.height,e.width];let c=Float32Array.from(e.data),d=[e.height,e.width,e.channels];if(this.do_rescale&&this.rescale(c),t??this.do_normalize){let u=this.image_mean;Array.isArray(this.image_mean)||(u=new Array(e.channels).fill(u));let p=this.image_std;if(Array.isArray(this.image_std)||(p=new Array(e.channels).fill(u)),u.length!==e.channels||p.length!==e.channels)throw new Error(`When set to arrays, the length of \`image_mean\` (${u.length}) and \`image_std\` (${p.length}) must match the number of channels in the image (${e.channels}).`);for(let m=0;m<c.length;m+=e.channels)for(let _=0;_<e.channels;++_)c[m+_]=(c[m+_]-this.image_mean[_])/this.image_std[_]}(s??(this.do_pad&&this.pad_size))&&([c,d]=this.pad_image(c,[e.width,e.height,e.channels],this.pad_size));const h=new z("float32",c,d),f=ve(h,[2,0,1]);return{original_size:[r,n],reshaped_input_size:l,pixel_values:f}}async _call(e,...t){Array.isArray(e)||(e=[e]);const s=await Promise.all(e.map(o=>this.preprocess(o)));return{pixel_values:ie(s.map(o=>o.pixel_values),0),original_sizes:s.map(o=>o.original_size),reshaped_input_sizes:s.map(o=>o.reshaped_input_size)}}}class dt extends k{post_process_semantic_segmentation(e,t=null){const s=e.logits,a=s.dims[0];if(t!==null&&t.length!==a)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");const o=[];for(let n=0;n<a;++n){const r=t!==null?t[n]:null;let l=s[n];r!==null&&(l=Q(l,r,"bilinear",!1));const[c,d]=r??l.dims.slice(-2),h=new z("int32",new Int32Array(c*d),[c,d]),f=l[0].data;for(let _=1;_<l.dims[0];++_){const g=l[_].data;for(let M=0;M<g.length;++M)g[M]>f[M]&&(f[M]=g[M],h.data[M]=_)}const u=new Array(l.dims[0]),p=h.data;for(let _=0;_<p.length;++_){const g=p[_];u[g]=g}const m=u.filter(_=>_!==void 0);o.push({segmentation:h,labels:m})}return o}}class ut extends k{}class ht extends k{}class ft extends k{}class pt extends k{}class mt extends k{}class _t extends k{}class gt extends k{}class be extends k{constructor(e){super(e),this.crop_pct=this.config.crop_pct??224/256}async resize(e){var s;const t=(s=this.size)==null?void 0:s.shortest_edge;if(t===void 0)throw new Error("Size dictionary must contain 'shortest_edge' key.");if(t<384){const a=Math.floor(t/this.crop_pct),[o,n]=this.get_resize_output_image_size(e,{shortest_edge:a});e=await e.resize(o,n,{resample:this.resample}),e=await e.center_crop(t,t)}else e=await e.resize(t,t,{resample:this.resample});return e}}class Mt extends be{}class bt extends k{}class wt extends k{}class yt extends k{}class we extends k{post_process_object_detection(...e){return le(...e)}}class Tt extends we{}class xt extends k{}class kt extends k{}class ye extends k{pad_image(e,t,s,a={}){const[o,n,r]=t;let l=this.image_mean;Array.isArray(this.image_mean)||(l=new Array(r).fill(l));let c=this.image_std;Array.isArray(c)||(c=new Array(r).fill(l));const d=l.map((h,f)=>-h/this.image_std[f]);return super.pad_image(e,t,s,{center:!0,constant_values:d,...a})}}class Ft extends ye{}class At extends k{async _call(e){const t=await super._call(e),s=[t.pixel_values.dims[0],64,64],a=new z("int64",new BigInt64Array(s.reduce((o,n)=>o*n)).fill(1n),s);return{...t,pixel_mask:a}}post_process_object_detection(...e){return le(...e)}remove_low_and_no_objects(e,t,s,a){let o=[],n=[],r=[];for(let l=0;l<e.dims[0];++l){let c=e[l],d=t[l],h=j(c.data)[1];if(h===a)continue;let u=E(c.data)[h];u>s&&(o.push(d),n.push(u),r.push(h))}return[o,n,r]}check_segment_validity(e,t,s,a=.5,o=.8){let n=[],r=0,l=0;for(let d=0;d<e.length;++d)e[d]===s&&(n.push(d),++r),t[s].data[d]>=a&&++l;let c=r>0&&l>0;return c&&(c=r/l>o),[c,n]}compute_segments(e,t,s,a,o,n=null,r=null){let[l,c]=r??e[0].dims,d=new z("int32",new Int32Array(l*c),[l,c]),h=[];if(r!==null)for(let m=0;m<e.length;++m)e[m]=Q(e[m],r,"bilinear",!1);let f=new Int32Array(e[0].data.length),u=new Float32Array(e[0].data.length);for(let m=0;m<e.length;++m){let _=t[m];for(let g=0;g<e[m].data.length;++g)e[m].data[g]*=_,e[m].data[g]>u[g]&&(f[g]=m,u[g]=e[m].data[g])}let p=0;for(let m=0;m<s.length;++m){let _=s[m],[g,M]=this.check_segment_validity(f,e,m,a,o);if(g){++p;for(let b of M)d.data[b]=p;h.push({id:p,label_id:_,score:t[m]})}}return[d,h]}post_process_panoptic_segmentation(e,t=.5,s=.5,a=.8,o=null,n=null){o===null&&(console.warn("`label_ids_to_fuse` unset. No instance will be fused."),o=new Set);const r=e.logits,c=e.pred_masks.sigmoid();let[d,h,f]=r.dims;if(f-=1,n!==null&&n.length!==d)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let u=[];for(let p=0;p<d;++p){let m=n!==null?n[p]:null,_=r[p],g=c[p],[M,b,w]=this.remove_low_and_no_objects(_,g,t,f);if(w.length===0){let[F,B]=m??g.dims.slice(-2),G=new z("int32",new Int32Array(F*B).fill(-1),[F,B]);u.push({segmentation:G,segments_info:[]});continue}let[y,T]=this.compute_segments(M,b,w,s,a,o,m);u.push({segmentation:y,segments_info:T})}return u}post_process_instance_segmentation(){throw Error("Not implemented yet")}}class Pt extends k{post_process_object_detection(...e){return le(...e)}}class zt extends k{reshape_input_points(e,t,s){e=structuredClone(e);let a=de(e);if(a.length===3)a=[1,...a],e=[e];else if(a.length!==4)throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");for(let o=0;o<e.length;++o){let n=t[o],r=s[o],l=[r[0]/n[0],r[1]/n[1]];for(let c=0;c<e[o].length;++c)for(let d=0;d<e[o][c].length;++d)for(let h=0;h<e[o][c][d].length;++h)e[o][c][d][h]*=l[h]}return new z("float32",Float32Array.from(e.flat(1/0)),a)}add_input_labels(e,t){let s=de(e);if(s.length===2)s=[1,...s],e=[e];else if(s.length!==3)throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");if(s.some((a,o)=>a!==t.dims[o]))throw Error(`The first ${s.length} dimensions of 'input_points' and 'input_labels' must be the same.`);return new z("int64",e.flat(1/0).map(BigInt),s)}async _call(e,t=null,s=null){const a=await super._call(e);if(t&&(a.input_points=this.reshape_input_points(t,a.original_sizes,a.reshaped_input_sizes)),s){if(!a.input_points)throw Error("`input_points` must be provided if `input_labels` are provided.");a.input_labels=this.add_input_labels(s,a.input_points)}return a}post_process_masks(e,t,s,{mask_threshold:a=0,binarize:o=!0,pad_size:n=null}={}){const r=[];n=n??this.pad_size;const l=[n.height,n.width];for(let c=0;c<t.length;++c){const d=t[c],h=s[c],f=e[c],u=[];for(let p=0;p<f.dims[0];++p){const m=f[p];let _=Q(m,l,"bilinear",!1);if(_=_.slice(null,[0,h[0]],[0,h[1]]),_=Q(_,d,"bilinear",!1),o){const g=new Uint8Array(_.data.length);for(let M=0;M<_.data.length;++M)_.data[M]>a&&(g[M]=1);_=new z("bool",g,_.dims)}u.push(_)}r.push(ie(u))}return r}}class Ct extends k{pad_image(e,t,s,a={}){const[o,n,r]=t;return super.pad_image(e,t,{width:o+(s-o%s)%s,height:n+(s-n%s)%s},{mode:"symmetric",center:!1,constant_values:-1,...a})}}class St extends k{async _call(e,t){Array.isArray(e)||(e=[e]),Array.isArray(t)||(t=[t]);const s=await Promise.all(e.map(n=>this.preprocess(n))),a=await Promise.all(t.map(n=>this.preprocess(n,{do_normalize:!1,do_convert_rgb:!1,do_convert_grayscale:!0})));return{pixel_values:ie(s.map((n,r)=>Ee([n.pixel_values,a[r].pixel_values],0)),0),original_sizes:s.map(n=>n.original_size),reshaped_input_sizes:s.map(n=>n.reshaped_input_size)}}}class vt extends V{constructor(e){var t;super(e),(t=this.config).mel_filters??(t.mel_filters=U(Math.floor(1+this.config.n_fft/2),this.config.feature_size,0,8e3,this.config.sampling_rate,"slaney","slaney")),this.window=oe(this.config.n_fft,"hann")}_extract_fbank_features(e){const{data:t,dims:s}=se(e,this.window,this.config.n_fft,this.config.hop_length,{power:2,mel_filters:this.config.mel_filters,log_mel:"log10",max_num_frames:this.config.nb_max_frames}),a=j(t)[0];for(let o=0;o<t.length;++o)t[o]=(Math.max(t[o],a-8)+4)/4;return{data:t,dims:s}}async _call(e){Z(e,"WhisperFeatureExtractor");let t;e.length>this.config.n_samples?(console.warn("Attempting to extract features for audio longer than 30 seconds. If using a pipeline to extract transcript from a long audio clip, remember to specify `chunk_length_s` and/or `stride_length_s`."),t=e.slice(0,this.config.n_samples)):(t=new Float32Array(this.config.n_samples),t.set(e));const{data:s,dims:a}=this._extract_fbank_features(t);return{input_features:new z("float32",s,[1,...a])}}}class Et extends V{_zero_mean_unit_var_norm(e){const s=e.reduce((o,n)=>o+n,0)/e.length,a=e.reduce((o,n)=>o+(n-s)**2,0)/e.length;return e.map(o=>(o-s)/Math.sqrt(a+1e-7))}async _call(e){Z(e,"Wav2Vec2FeatureExtractor"),e instanceof Float64Array&&(e=new Float32Array(e));let t=e;this.config.do_normalize&&(t=this._zero_mean_unit_var_norm(t));const s=[1,t.length];return{input_values:new z("float32",t,s),attention_mask:new z("int64",new BigInt64Array(t.length).fill(1n),s)}}}class Lt extends V{constructor(e){super(e);const t=this.config.sampling_rate,s=U(256,this.config.num_mel_bins,20,Math.floor(t/2),t,null,"kaldi",!0);for(let a=0;a<s.length;++a)s[a].push(0);this.mel_filters=s,this.window=oe(400,"povey",{periodic:!1})}_extract_fbank_features(e,t){return e=e.map(s=>s*32768),se(e,this.window,400,160,{fft_length:512,power:2,center:!1,preemphasis:.97,mel_filters:this.mel_filters,log_mel:"log",mel_floor:1192092955078125e-22,remove_dc_offset:!0,max_num_frames:t,transpose:!0})}async _call(e,{padding:t=!0,pad_to_multiple_of:s=2,do_normalize_per_mel_bins:a=!0,return_attention_mask:o=!0}={}){Z(e,"SeamlessM4TFeatureExtractor");let n=this._extract_fbank_features(e,this.config.max_length);if(a){const[p,m]=n.dims;for(let _=0;_<m;++_){let g=0;for(let y=0;y<p;++y)g+=n.data[y*m+_];const M=g/p;let b=0;for(let y=0;y<p;++y)b+=(n.data[y*m+_]-M)**2;b/=p-1;const w=Math.sqrt(b+1e-7);for(let y=0;y<p;++y){const T=y*m+_;n.data[T]=(n.data[T]-M)/w}}}let r;if(t){const[p,m]=n.dims,_=p%s;if(_>0){const g=new Float32Array(m*(p+_));g.set(n.data),g.fill(this.config.padding_value,n.data.length);const M=p+_;n={data:g,dims:[M,m]},o&&(r=new z("int64",new BigInt64Array(M),[1,M]),r.data.fill(1n,0,p))}}const[l,c]=n.dims,d=this.config.stride;if(l%d!==0)throw new Error(`The number of frames (${l}) must be a multiple of the stride (${d}).`);const f=new z("float32",n.data,n.dims).view(1,Math.floor(l/d),c*d),u={input_features:f};if(o){const p=f.dims[1],m=new z("int64",new BigInt64Array(p),[1,p]);if(r)for(let _=1,g=0;_<l;_+=d,++g)m.data[g]=r.data[_];else m.data.fill(1n);u.attention_mask=m}return u}}class It extends V{constructor(e){super(e);const t=this.config.sampling_rate,s=U(256,this.config.num_mel_bins,20,Math.floor(t/2),t,null,"kaldi",!0);for(let a=0;a<s.length;++a)s[a].push(0);this.mel_filters=s,this.window=oe(400,"hann",{periodic:!1}),this.mean=this.config.mean,this.std=this.config.std}_extract_fbank_features(e,t){return se(e,this.window,400,160,{fft_length:512,power:2,center:!1,preemphasis:.97,mel_filters:this.mel_filters,log_mel:"log",mel_floor:1192092955078125e-22,remove_dc_offset:!0,max_num_frames:t,transpose:!0})}async _call(e){Z(e,"ASTFeatureExtractor");const t=this._extract_fbank_features(e,this.config.max_length);if(this.config.do_normalize){const s=this.std*2;for(let a=0;a<t.data.length;++a)t.data[a]=(t.data[a]-this.mean)/s}return{input_values:new z("float32",t.data,[1,...t.dims])}}}class Bt extends V{constructor(e){super(e),this.mel_filters=U(this.config.nb_frequency_bins,this.config.feature_size,this.config.frequency_min,this.config.frequency_max,this.config.sampling_rate,null,"htk"),this.mel_filters_slaney=U(this.config.nb_frequency_bins,this.config.feature_size,this.config.frequency_min,this.config.frequency_max,this.config.sampling_rate,"slaney","slaney"),this.window=oe(this.config.fft_window_size,"hann")}_get_input_mel(e,t,s,a){let o,n=!1;const r=e.length-t;if(r>0)if(s==="rand_trunc"){n=!0;const l=Math.floor(Math.random()*(r+1));e=e.subarray(l,l+t),o=this._extract_fbank_features(e,this.mel_filters_slaney,this.config.nb_max_samples),o.dims=[1,...o.dims]}else throw new Error(`Truncation strategy "${s}" not implemented`);else{if(r<0){let l=new Float64Array(t);if(l.set(e),a==="repeat")for(let c=e.length;c<t;c+=e.length)l.set(e.subarray(0,Math.min(e.length,t-c)),c);else if(a==="repeatpad")for(let c=e.length;c<-r;c+=e.length)l.set(e,c);e=l}if(s==="fusion")throw new Error(`Truncation strategy "${s}" not implemented`);o=this._extract_fbank_features(e,this.mel_filters_slaney,this.config.nb_max_samples),o.dims=[1,...o.dims]}return{...o,longer:n}}_extract_fbank_features(e,t,s=null){return se(e,this.window,this.config.fft_window_size,this.config.hop_length,{power:2,mel_filters:t,log_mel:"dB",max_num_frames:s,do_pad:!1,transpose:!0})}async _call(e,{max_length:t=null}={}){Z(e,"ClapFeatureExtractor");const s=this._get_input_mel(e,t??this.config.nb_max_samples,this.config.truncation,this.config.padding);return{input_features:new z("float32",s.data,[1,...s.dims])}}}class Rt extends V{}class $ extends re{constructor(e){super(),this.feature_extractor=e}async _call(e,...t){return await this.feature_extractor(e,...t)}}class Dt extends ${async _call(...e){return await this.feature_extractor(...e)}post_process_masks(...e){return this.feature_extractor.post_process_masks(...e)}reshape_input_points(...e){return this.feature_extractor.reshape_input_points(...e)}}class Ot extends ${async _call(e){return await this.feature_extractor(e)}}class jt extends ${async _call(e){return await this.feature_extractor(e)}}class qt extends ${async _call(e){return await this.feature_extractor(e)}}class Nt extends ${}class v{static async from_pretrained(e,{progress_callback:t=null,config:s=null,cache_dir:a=null,local_files_only:o=!1,revision:n="main"}={}){let r=s??await Ce(e,"preprocessor_config.json",!0,{progress_callback:t,config:s,cache_dir:a,local_files_only:o,revision:n}),l=r.feature_extractor_type??r.image_processor_type,c=this.FEATURE_EXTRACTOR_CLASS_MAPPING[l];if(!c)if(r.size!==void 0)console.warn(`Feature extractor type "${l}" not found, assuming ImageFeatureExtractor due to size parameter in config.`),c=k;else throw new Error(`Unknown Feature Extractor type: ${l}`);let d=this.PROCESSOR_CLASS_MAPPING[r.processor_class]??$,h=new c(r);return new d(h)}}N(v,"FEATURE_EXTRACTOR_CLASS_MAPPING",{ImageFeatureExtractor:k,WhisperFeatureExtractor:vt,ViTFeatureExtractor:bt,MobileViTFeatureExtractor:yt,OwlViTFeatureExtractor:we,Owlv2ImageProcessor:Tt,CLIPFeatureExtractor:mt,ChineseCLIPFeatureExtractor:_t,SiglipImageProcessor:gt,ConvNextFeatureExtractor:be,ConvNextImageProcessor:Mt,SegformerFeatureExtractor:dt,BitImageProcessor:ht,DPTImageProcessor:ut,DPTFeatureExtractor:ft,GLPNFeatureExtractor:pt,BeitFeatureExtractor:kt,DeiTFeatureExtractor:xt,DetrFeatureExtractor:At,YolosFeatureExtractor:Pt,DonutFeatureExtractor:ye,NougatImageProcessor:Ft,ViTImageProcessor:wt,VitMatteImageProcessor:St,SamImageProcessor:zt,Swin2SRImageProcessor:Ct,Wav2Vec2FeatureExtractor:Et,SeamlessM4TFeatureExtractor:Lt,SpeechT5FeatureExtractor:Rt,ASTFeatureExtractor:It,ClapFeatureExtractor:Bt}),N(v,"PROCESSOR_CLASS_MAPPING",{WhisperProcessor:Ot,Wav2Vec2ProcessorWithLM:jt,SamProcessor:Dt,SpeechT5Processor:qt,OwlViTProcessor:Nt});async function O(i){return Array.isArray(i)||(i=[i]),await Promise.all(i.map(e=>H.read(e)))}async function ee(i,e){return Array.isArray(i)||(i=[i]),await Promise.all(i.map(t=>typeof t=="string"||t instanceof URL?tt(t,e):t instanceof Float64Array?new Float32Array(t):t))}function Te(i,e){e&&(i=i.map(n=>n|0));const[t,s,a,o]=i;return{xmin:t,ymin:s,xmax:a,ymax:o}}class A extends re{constructor({task:e,model:t,tokenizer:s=null,processor:a=null}){super(),this.task=e,this.model=t,this.tokenizer=s,this.processor=a}async dispose(){await this.model.dispose()}}class Vt extends A{constructor(e){super(e)}async _call(e,{topk:t=1}={}){const s=this.tokenizer(e,{padding:!0,truncation:!0}),a=await this.model(s),o=this.model.config.problem_type==="multi_label_classification"?l=>l.sigmoid().data:l=>E(l.data),n=this.model.config.id2label,r=[];for(const l of a.logits){const c=o(l),h=te(c,t).map(f=>({label:n[f[0]],score:f[1]}));t===1?r.push(...h):r.push(h)}return Array.isArray(e)||t===1?r:r[0]}}class Gt extends A{constructor(e){super(e)}async _call(e,{ignore_labels:t=["O"]}={}){const s=Array.isArray(e),a=this.tokenizer(s?e:[e],{padding:!0,truncation:!0}),n=(await this.model(a)).logits,r=this.model.config.id2label,l=[];for(let c=0;c<n.dims[0];++c){const d=a.input_ids[c],h=n[c],f=[];for(let u=0;u<h.dims[0];++u){const p=h[u],m=j(p.data)[1],_=r?r[m]:`LABEL_${m}`;if(t.includes(_))continue;const g=this.tokenizer.decode([d[u].item()],{skip_special_tokens:!0});if(g==="")continue;const M=E(p.data);f.push({entity:_,score:M[m],index:u,word:g,start:null,end:null})}l.push(f)}return s?l:l[0]}}class Xt extends A{constructor(e){super(e)}async _call(e,t,{topk:s=1}={}){const a=this.tokenizer(e,{text_pair:t,padding:!0,truncation:!0}),o=await this.model(a),n=[];for(let r=0;r<o.start_logits.dims[0];++r){const l=a.input_ids[r],c=l.indexOf(this.tokenizer.sep_token_id),d=Array.from(E(o.start_logits[r].data)).map((u,p)=>[u,p]).filter(u=>u[1]>c),h=Array.from(E(o.end_logits[r].data)).map((u,p)=>[u,p]).filter(u=>u[1]>c),f=Ye(d,h).filter(u=>u[0][1]<=u[1][1]).map(u=>[u[0][1],u[1][1],u[0][0]*u[1][0]]).sort((u,p)=>p[2]-u[2]);for(let u=0;u<Math.min(f.length,s);++u){const[p,m,_]=f[u],g=[...l].slice(p,m+1),M=this.tokenizer.decode(g,{skip_special_tokens:!0});n.push({answer:M,score:_})}}return s===1?n[0]:n}}class Wt extends A{constructor(e){super(e)}async _call(e,{topk:t=5}={}){const s=this.tokenizer(e,{padding:!0,truncation:!0}),a=await this.model(s),o=[];for(let n=0;n<s.input_ids.dims[0];++n){const r=s.input_ids[n],l=r.indexOf(this.tokenizer.mask_token_id);if(l===-1)throw Error(`Mask token (${this.tokenizer.mask_token}) not found in text.`);const d=a.logits[n][l],h=te(E(d.data),t);o.push(h.map(f=>{const u=[...r];return u[l]=f[0],{score:f[1],token:f[0],token_str:this.tokenizer.model.vocab[f[0]],sequence:this.tokenizer.decode(u,{skip_special_tokens:!0})}}))}return Array.isArray(e)?o:o[0]}}class ce extends A{constructor(t){super(t);N(this,"_key","generated_text")}async _call(t,s={}){Array.isArray(t)||(t=[t]),this.model.config.prefix&&(t=t.map(c=>this.model.config.prefix+c));const a=this.model.config.task_specific_params;a&&a[this.task]&&a[this.task].prefix&&(t=t.map(c=>a[this.task].prefix+c));const o=this.tokenizer,n={padding:!0,truncation:!0};let r;this instanceof xe&&"_build_translation_inputs"in o?r=o._build_translation_inputs(t,n,s).input_ids:r=o(t,n).input_ids;const l=await this.model.generate(r,s);return o.batch_decode(l,{skip_special_tokens:!0}).map(c=>({[this._key]:c}))}}class $t extends ce{constructor(t){super(t);N(this,"_key","summary_text")}}class xe extends ce{constructor(t){super(t);N(this,"_key","translation_text")}}class Qt extends A{constructor(e){super(e)}async _call(e,t={}){const s=Array.isArray(e);s||(e=[e]);const a=t.add_special_tokens??!1;this.tokenizer.padding_side="left";const{input_ids:o,attention_mask:n}=this.tokenizer(e,{add_special_tokens:a,padding:!0,truncation:!0}),r=await this.model.generate(o,t,null,{inputs_attention_mask:n}),l=this.tokenizer.batch_decode(r,{skip_special_tokens:!0}),c=Array.from({length:e.length},d=>[]);for(let d=0;d<l.length;++d){const h=Math.floor(d/r.length*e.length);c[h].push({generated_text:l[d]})}return!s&&c.length===1?c[0]:c}}class Ht extends A{constructor(e){super(e),this.label2id=Object.fromEntries(Object.entries(this.model.config.label2id).map(([t,s])=>[t.toLowerCase(),s])),this.entailment_id=this.label2id.entailment,this.entailment_id===void 0&&(console.warn("Could not find 'entailment' in label2id mapping. Using 2 as entailment_id."),this.entailment_id=2),this.contradiction_id=this.label2id.contradiction??this.label2id.not_entailment,this.contradiction_id===void 0&&(console.warn("Could not find 'contradiction' in label2id mapping. Using 0 as contradiction_id."),this.contradiction_id=0)}async _call(e,t,{hypothesis_template:s="This example is {}.",multi_label:a=!1}={}){const o=Array.isArray(e);o||(e=[e]),Array.isArray(t)||(t=[t]);const n=t.map(c=>s.replace("{}",c)),r=a||t.length===1,l=[];for(const c of e){const d=[];for(const u of n){const p=this.tokenizer(c,{text_pair:u,padding:!0,truncation:!0}),m=await this.model(p);r?d.push([m.logits.data[this.contradiction_id],m.logits.data[this.entailment_id]]):d.push(m.logits.data[this.entailment_id])}const f=(r?d.map(u=>E(u)[1]):E(d)).map((u,p)=>[u,p]).sort((u,p)=>p[0]-u[0]);l.push({sequence:c,labels:f.map(u=>t[u[1]]),scores:f.map(u=>u[0])})}return o?l:l[0]}}class Ut extends A{constructor(e){super(e)}async _call(e,{pooling:t="none",normalize:s=!1}={}){const a=this.tokenizer(e,{padding:!0,truncation:!0}),o=await this.model(a);let n=o.last_hidden_state??o.logits;if(t!=="none")if(t==="mean")n=Ke(n,a.attention_mask);else if(t==="cls")n=n.slice(null,0);else throw Error(`Pooling method '${t}' not supported.`);return s&&(n=n.normalize(2,-1)),n}}class Zt extends A{constructor(e){super(e)}async _call(e,{topk:t=null}={}){const s=!Array.isArray(e),a=this.processor.feature_extractor.config.sampling_rate,o=await ee(e,a),n=this.model.config.id2label,r=[];for(const l of o){const c=await this.processor(l),h=(await this.model(c)).logits[0],u=te(E(h.data),t).map(p=>({label:n[p[0]],score:p[1]}));t===1?r.push(...u):r.push(u)}return!s||t===1?r:r[0]}}class Jt extends A{constructor(e){super(e)}async _call(e,t,{hypothesis_template:s="This is a sound of {}."}={}){const a=!Array.isArray(e);a&&(e=[e]);const o=t.map(d=>s.replace("{}",d)),n=this.tokenizer(o,{padding:!0,truncation:!0}),r=this.processor.feature_extractor.config.sampling_rate,l=await ee(e,r),c=[];for(const d of l){const h=await this.processor(d),f=await this.model({...n,...h}),u=E(f.logits_per_audio.data);c.push([...u].map((p,m)=>({score:p,label:t[m]})))}return a?c[0]:c}}class Yt extends A{constructor(e){super(e)}async _call(e,t={}){switch(this.model.config.model_type){case"whisper":return this._call_whisper(e,t);case"wav2vec2":case"wav2vec2-bert":case"hubert":return this._call_wav2vec2(e,t);default:throw new Error(`AutomaticSpeechRecognitionPipeline does not support model type '${this.model.config.model_type}'.`)}}async _call_wav2vec2(e,t={}){t.language&&console.warn('`language` parameter is not yet supported for `wav2vec2` models, defaulting to "English".'),t.task&&console.warn('`task` parameter is not yet supported for `wav2vec2` models, defaulting to "transcribe".');const s=!Array.isArray(e);s&&(e=[e]);const a=this.processor.feature_extractor.config.sampling_rate,o=await ee(e,a),n=[];for(const r of o){const l=await this.processor(r),d=(await this.model(l)).logits[0],h=[];for(const u of d)h.push(j(u.data)[1]);const f=this.tokenizer.decode(h);n.push({text:f})}return s?n[0]:n}async _call_whisper(e,t={}){const s=t.return_timestamps??!1,a=t.chunk_length_s??0,o=t.chunk_callback??null,n=t.force_full_sequences??!1;let r=t.stride_length_s??null;s==="word"&&(t.return_token_timestamps=!0);const l=he(t,"language",null),c=he(t,"task",null);if(l||c||s){if(t.forced_decoder_ids)throw new Error("Cannot specify `language`/`task`/`return_timestamps` and `forced_decoder_ids` at the same time.");const _=this.tokenizer.get_decoder_prompt_ids({language:l,task:c,no_timestamps:!s});_.length>0&&(t.forced_decoder_ids=_)}const d=!Array.isArray(e);d&&(e=[e]);const h=this.processor.feature_extractor.config.chunk_length/this.model.config.max_source_positions,f=this.processor.feature_extractor.config.hop_length,u=this.processor.feature_extractor.config.sampling_rate,p=await ee(e,u),m=[];for(const _ of p){let g=[];if(a>0){if(r===null)r=a/6;else if(a<=r)throw Error("`chunk_length_s` must be larger than `stride_length_s`.");const w=u*a,y=u*r,T=w-2*y;let F=0;for(;F<_.length;){const B=_.subarray(F,F+w),G=await this.processor(B),R=F===0,X=F+T>=_.length;g.push({stride:[B.length,R?0:y,X?0:y],input_features:G.input_features,is_last:X}),F+=T}}else g=[{stride:[_.length,0,0],input_features:(await this.processor(_)).input_features,is_last:!0}];for(const w of g){t.num_frames=Math.floor(w.stride[0]/f);const y=await this.model.generate(w.input_features,t);s==="word"?(w.tokens=y.sequences[0],w.token_timestamps=y.token_timestamps.tolist()[0].map(T=>et(T,2))):w.tokens=y[0],w.stride=w.stride.map(T=>T/u),o!==null&&o(w)}const[M,b]=this.tokenizer._decode_asr(g,{time_precision:h,return_timestamps:s,force_full_sequences:n});m.push({text:M,...b})}return d?m[0]:m}}class Kt extends A{constructor(e){super(e)}async _call(e,t={}){const s=Array.isArray(e),a=await O(e),{pixel_values:o}=await this.processor(a),n=[];for(const r of o){r.dims=[1,...r.dims];const l=await this.model.generate(r,t),c=this.tokenizer.batch_decode(l,{skip_special_tokens:!0}).map(d=>({generated_text:d.trim()}));n.push(c)}return s?n:n[0]}}class es extends A{constructor(e){super(e)}async _call(e,{topk:t=1}={}){const s=Array.isArray(e),a=await O(e),{pixel_values:o}=await this.processor(a),n=await this.model({pixel_values:o}),r=this.model.config.id2label,l=[];for(const c of n.logits){const h=te(E(c.data),t).map(f=>({label:r[f[0]],score:f[1]}));t===1?l.push(...h):l.push(h)}return s||t===1?l:l[0]}}class ts extends A{constructor(e){super(e),this.subtasks_mapping={panoptic:"post_process_panoptic_segmentation",instance:"post_process_instance_segmentation",semantic:"post_process_semantic_segmentation"}}async _call(e,{threshold:t=.5,mask_threshold:s=.5,overlap_mask_area_threshold:a=.8,label_ids_to_fuse:o=null,target_sizes:n=null,subtask:r=null}={}){if(Array.isArray(e)&&e.length!==1)throw Error("Image segmentation pipeline currently only supports a batch size of 1.");const c=await O(e),d=c.map(g=>[g.height,g.width]),{pixel_values:h,pixel_mask:f}=await this.processor(c),u=await this.model({pixel_values:h,pixel_mask:f});let p=null;if(r!==null)p=this.subtasks_mapping[r];else for(let[g,M]of Object.entries(this.subtasks_mapping))if(M in this.processor.feature_extractor){p=this.processor.feature_extractor[M].bind(this.processor.feature_extractor),r=g;break}const m=this.model.config.id2label,_=[];if(r==="panoptic"||r==="instance"){const g=p(u,t,s,a,o,n??d)[0],M=g.segmentation;for(const b of g.segments_info){const w=new Uint8ClampedArray(M.data.length);for(let T=0;T<M.data.length;++T)M.data[T]===b.id&&(w[T]=255);const y=new H(w,M.dims[1],M.dims[0],1);_.push({score:b.score,label:m[b.label_id],mask:y})}}else if(r==="semantic"){const{segmentation:g,labels:M}=p(u,n??d)[0];for(const b of M){const w=new Uint8ClampedArray(g.data.length);for(let T=0;T<g.data.length;++T)g.data[T]===b&&(w[T]=255);const y=new H(w,g.dims[1],g.dims[0],1);_.push({score:null,label:m[b],mask:y})}}else throw Error(`Subtask ${r} not supported.`);return _}}class ss extends A{constructor(e){super(e)}async _call(e,t,{hypothesis_template:s="This is a photo of {}"}={}){const a=Array.isArray(e),o=await O(e),n=t.map(f=>s.replace("{}",f)),r=this.tokenizer(n,{padding:this.model.config.model_type==="siglip"?"max_length":!0,truncation:!0}),{pixel_values:l}=await this.processor(o),c=await this.model({...r,pixel_values:l}),d=this.model.config.model_type==="siglip"?f=>f.sigmoid().data:f=>E(f.data),h=[];for(const f of c.logits_per_image){const p=[...d(f)].map((m,_)=>({score:m,label:t[_]}));p.sort((m,_)=>_.score-m.score),h.push(p)}return a?h:h[0]}}class os extends A{constructor(e){super(e)}async _call(e,{threshold:t=.9,percentage:s=!1}={}){const a=Array.isArray(e);if(a&&e.length!==1)throw Error("Object detection pipeline currently only supports a batch size of 1.");const o=await O(e),n=s?null:o.map(u=>[u.height,u.width]),{pixel_values:r,pixel_mask:l}=await this.processor(o),c=await this.model({pixel_values:r,pixel_mask:l}),d=this.processor.feature_extractor.post_process_object_detection(c,t,n),h=this.model.config.id2label,f=d.map(u=>u.boxes.map((p,m)=>({score:u.scores[m],label:h[u.classes[m]],box:Te(p,!s)})));return a?f:f[0]}}class as extends A{constructor(e){super(e)}async _call(e,t,{threshold:s=.1,topk:a=null,percentage:o=!1}={}){const n=Array.isArray(e),r=await O(e),l=this.tokenizer(t,{padding:!0,truncation:!0}),c=await this.processor(r),d=[];for(let h=0;h<r.length;++h){const f=r[h],u=o?null:[[f.height,f.width]],p=c.pixel_values[h].unsqueeze_(0),m=await this.model({...l,pixel_values:p}),_=this.processor.feature_extractor.post_process_object_detection(m,s,u,!0)[0];let g=_.boxes.map((M,b)=>({score:_.scores[b],label:t[_.classes[b]],box:Te(M,!o)})).sort((M,b)=>b.score-M.score);a!==null&&(g=g.slice(0,a)),d.push(g)}return n?d:d[0]}}class ns extends A{constructor(e){super(e)}async _call(e,t,s={}){const a=(await O(e))[0],{pixel_values:o}=await this.processor(a),n=`<s_docvqa><s_question>${t}</s_question><s_answer>`,r=this.tokenizer(n,{add_special_tokens:!1,padding:!0,truncation:!0}).input_ids,l=await this.model.generate(o,{...s,decoder_input_ids:r,max_length:this.model.config.decoder.max_position_embeddings}),d=this.tokenizer.batch_decode(l)[0].match(/<s_answer>(.*?)<\/s_answer>/);let h=null;return d&&d.length>=2&&(h=d[1].trim()),[{answer:h}]}}class is extends A{constructor(t){super(t);N(this,"DEFAULT_VOCODER_ID","Xenova/speecht5_hifigan");this.vocoder=t.vocoder??null}async _call(t,{speaker_embeddings:s=null}={}){return this.processor?this._call_text_to_spectrogram(t,{speaker_embeddings:s}):this._call_text_to_waveform(t)}async _call_text_to_waveform(t){const s=this.tokenizer(t,{padding:!0,truncation:!0}),{waveform:a}=await this.model(s),o=this.model.config.sampling_rate;return{audio:a.data,sampling_rate:o}}async _call_text_to_spectrogram(t,{speaker_embeddings:s}){if(this.vocoder||(console.log("No vocoder specified, using default HifiGan vocoder."),this.vocoder=await Y.from_pretrained(this.DEFAULT_VOCODER_ID,{quantized:!1})),(typeof s=="string"||s instanceof URL)&&(s=new Float32Array(await(await fetch(s)).arrayBuffer())),s instanceof Float32Array)s=new z("float32",s,[1,s.length]);else if(!(s instanceof z))throw new Error("Speaker embeddings must be a `Tensor`, `Float32Array`, `string`, or `URL`.");const{input_ids:a}=this.tokenizer(t,{padding:!0,truncation:!0}),{waveform:o}=await this.model.generate_speech(a,s,{vocoder:this.vocoder}),n=this.processor.feature_extractor.config.sampling_rate;return{audio:o.data,sampling_rate:n}}}class rs extends A{constructor(e){super(e)}async _call(e){const t=await O(e),s=await this.processor(t),a=await this.model(s),o=[];for(const n of a.reconstruction){const r=n.squeeze().clamp_(0,1).mul_(255).round_().to("uint8");o.push(H.fromTensor(r))}return o.length>1?o:o[0]}}class ls extends A{constructor(e){super(e)}async _call(e){const t=await O(e),s=await this.processor(t),{predicted_depth:a}=await this.model(s),o=[];for(let n=0;n<t.length;++n){const r=Q(a[n],t[n].size.reverse(),"bilinear",!1),l=r.mul_(255/j(r.data)[0]).to("uint8");o.push({predicted_depth:a[n],depth:H.fromTensor(l)})}return o.length>1?o:o[0]}}const ge=Object.freeze({"text-classification":{tokenizer:S,pipeline:Vt,model:ue,default:{model:"Xenova/distilbert-base-uncased-finetuned-sst-2-english"},type:"text"},"token-classification":{tokenizer:S,pipeline:Gt,model:Ie,default:{model:"Xenova/bert-base-multilingual-cased-ner-hrl"},type:"text"},"question-answering":{tokenizer:S,pipeline:Xt,model:Be,default:{model:"Xenova/distilbert-base-cased-distilled-squad"},type:"text"},"fill-mask":{tokenizer:S,pipeline:Wt,model:Re,default:{model:"Xenova/bert-base-uncased"},type:"text"},summarization:{tokenizer:S,pipeline:$t,model:ae,default:{model:"Xenova/distilbart-cnn-6-6"},type:"text"},translation:{tokenizer:S,pipeline:xe,model:ae,default:{model:"Xenova/t5-small"},type:"text"},"text2text-generation":{tokenizer:S,pipeline:ce,model:ae,default:{model:"Xenova/flan-t5-small"},type:"text"},"text-generation":{tokenizer:S,pipeline:Qt,model:De,default:{model:"Xenova/gpt2"},type:"text"},"zero-shot-classification":{tokenizer:S,pipeline:Ht,model:ue,default:{model:"Xenova/distilbert-base-uncased-mnli"},type:"text"},"audio-classification":{pipeline:Zt,model:Oe,processor:v,default:{model:"Xenova/wav2vec2-base-superb-ks"},type:"audio"},"zero-shot-audio-classification":{tokenizer:S,pipeline:Jt,model:Y,processor:v,default:{model:"Xenova/clap-htsat-unfused"},type:"multimodal"},"automatic-speech-recognition":{tokenizer:S,pipeline:Yt,model:[je,qe],processor:v,default:{model:"Xenova/whisper-tiny.en"},type:"multimodal"},"text-to-audio":{tokenizer:S,pipeline:is,model:[Ne,Ve],processor:[v,null],default:{model:"Xenova/speecht5_tts"},type:"text"},"image-to-text":{tokenizer:S,pipeline:Kt,model:Ge,processor:v,default:{model:"Xenova/vit-gpt2-image-captioning"},type:"multimodal"},"image-classification":{pipeline:es,model:Xe,processor:v,default:{model:"Xenova/vit-base-patch16-224"},type:"multimodal"},"image-segmentation":{pipeline:ts,model:[We,$e],processor:v,default:{model:"Xenova/detr-resnet-50-panoptic"},type:"multimodal"},"zero-shot-image-classification":{tokenizer:S,pipeline:ss,model:Y,processor:v,default:{model:"Xenova/clip-vit-base-patch32"},type:"multimodal"},"object-detection":{pipeline:os,model:Qe,processor:v,default:{model:"Xenova/detr-resnet-50"},type:"multimodal"},"zero-shot-object-detection":{tokenizer:S,pipeline:as,model:He,processor:v,default:{model:"Xenova/owlvit-base-patch32"},type:"multimodal"},"document-question-answering":{tokenizer:S,pipeline:ns,model:Ue,processor:v,default:{model:"Xenova/donut-base-finetuned-docvqa"},type:"multimodal"},"image-to-image":{pipeline:rs,model:Ze,processor:v,default:{model:"Xenova/swin2SR-classical-sr-x2-64"},type:"image"},"depth-estimation":{pipeline:ls,model:Je,processor:v,default:{model:"Xenova/dpt-large"},type:"image"},"feature-extraction":{tokenizer:S,pipeline:Ut,model:Y,default:{model:"Xenova/all-MiniLM-L6-v2"},type:"text"}}),cs=Object.freeze({"sentiment-analysis":"text-classification",ner:"token-classification",asr:"automatic-speech-recognition","text-to-speech":"text-to-audio",embeddings:"feature-extraction"});async function fs(i,e=null,{quantized:t=!0,progress_callback:s=null,config:a=null,cache_dir:o=null,local_files_only:n=!1,revision:r="main"}={}){i=cs[i]??i;const l=ge[i.split("_",1)[0]];if(!l)throw Error(`Unsupported pipeline: ${i}. Must be one of [${Object.keys(ge)}]`);e||(e=l.default.model,console.log(`No model specified. Using default model: "${e}".`));const c={quantized:t,progress_callback:s,config:a,cache_dir:o,local_files_only:n,revision:r},d=new Map([["tokenizer",l.tokenizer],["model",l.model],["processor",l.processor]]),h=await ds(d,e,c);h.task=i,Le(s,{status:"ready",task:i,model:e});const f=l.pipeline;return new f(h)}async function ds(i,e,t){const s=Object.create(null),a=[];for(let[o,n]of i.entries()){if(!n)continue;let r;Array.isArray(n)?r=new Promise(async(l,c)=>{let d;for(let h of n){if(h===null){l(null);return}try{l(await h.from_pretrained(e,t));return}catch(f){d=f}}c(d)}):r=n.from_pretrained(e,t),s[o]=r,a.push(r)}await Promise.all(a);for(let[o,n]of Object.entries(s))s[o]=await n;return s}export{It as ASTFeatureExtractor,_s as ASTForAudioClassification,gs as ASTModel,Ms as ASTPreTrainedModel,bs as AlbertForMaskedLM,ws as AlbertForQuestionAnswering,ys as AlbertForSequenceClassification,Ts as AlbertModel,xs as AlbertPreTrainedModel,ks as AlbertTokenizer,Zt as AudioClassificationPipeline,Fs as AutoConfig,Y as AutoModel,Oe as AutoModelForAudioClassification,qe as AutoModelForCTC,De as AutoModelForCausalLM,Je as AutoModelForDepthEstimation,Ue as AutoModelForDocumentQuestionAnswering,Xe as AutoModelForImageClassification,We as AutoModelForImageSegmentation,Ze as AutoModelForImageToImage,Re as AutoModelForMaskedLM,Qe as AutoModelForObjectDetection,Be as AutoModelForQuestionAnswering,$e as AutoModelForSemanticSegmentation,ae as AutoModelForSeq2SeqLM,ue as AutoModelForSequenceClassification,je as AutoModelForSpeechSeq2Seq,Ve as AutoModelForTextToSpectrogram,Ne as AutoModelForTextToWaveform,Ie as AutoModelForTokenClassification,Ge as AutoModelForVision2Seq,He as AutoModelForZeroShotObjectDetection,v as AutoProcessor,S as AutoTokenizer,Yt as AutomaticSpeechRecognitionPipeline,As as BartForConditionalGeneration,Ps as BartForSequenceClassification,zs as BartModel,Cs as BartPretrainedModel,Ss as BartTokenizer,kt as BeitFeatureExtractor,vs as BeitForImageClassification,Es as BeitModel,Ls as BeitPreTrainedModel,Is as BertForMaskedLM,Bs as BertForQuestionAnswering,Rs as BertForSequenceClassification,Ds as BertForTokenClassification,Os as BertModel,js as BertPreTrainedModel,qs as BertTokenizer,ht as BitImageProcessor,Ns as BlenderbotForConditionalGeneration,Vs as BlenderbotModel,Gs as BlenderbotPreTrainedModel,Xs as BlenderbotSmallForConditionalGeneration,Ws as BlenderbotSmallModel,$s as BlenderbotSmallPreTrainedModel,Qs as BlenderbotSmallTokenizer,Hs as BlenderbotTokenizer,Us as BloomForCausalLM,Zs as BloomModel,Js as BloomPreTrainedModel,Ys as BloomTokenizer,mt as CLIPFeatureExtractor,Ks as CLIPModel,eo as CLIPPreTrainedModel,to as CLIPSegForImageSegmentation,so as CLIPSegModel,oo as CLIPSegPreTrainedModel,ao as CLIPTextModelWithProjection,no as CLIPTokenizer,io as CLIPVisionModelWithProjection,ro as CamembertForMaskedLM,lo as CamembertForQuestionAnswering,co as CamembertForSequenceClassification,uo as CamembertForTokenClassification,ho as CamembertModel,fo as CamembertPreTrainedModel,po as CamembertTokenizer,mo as CausalLMOutput,_t as ChineseCLIPFeatureExtractor,_o as ChineseCLIPModel,go as ChineseCLIPPreTrainedModel,Mo as ClapAudioModelWithProjection,Bt as ClapFeatureExtractor,bo as ClapModel,wo as ClapPreTrainedModel,yo as ClapTextModelWithProjection,To as CodeGenForCausalLM,xo as CodeGenModel,ko as CodeGenPreTrainedModel,Fo as CodeGenTokenizer,Ao as CodeLlamaTokenizer,Po as ConvBertForMaskedLM,zo as ConvBertForQuestionAnswering,Co as ConvBertForSequenceClassification,So as ConvBertForTokenClassification,vo as ConvBertModel,Eo as ConvBertPreTrainedModel,Lo as ConvBertTokenizer,be as ConvNextFeatureExtractor,Io as ConvNextForImageClassification,Mt as ConvNextImageProcessor,Bo as ConvNextModel,Ro as ConvNextPreTrainedModel,Do as ConvNextV2ForImageClassification,Oo as ConvNextV2Model,jo as ConvNextV2PreTrainedModel,ft as DPTFeatureExtractor,qo as DPTForDepthEstimation,ut as DPTImageProcessor,No as DPTModel,Vo as DPTPreTrainedModel,Go as DebertaForMaskedLM,Xo as DebertaForQuestionAnswering,Wo as DebertaForSequenceClassification,$o as DebertaForTokenClassification,Qo as DebertaModel,Ho as DebertaPreTrainedModel,Uo as DebertaTokenizer,Zo as DebertaV2ForMaskedLM,Jo as DebertaV2ForQuestionAnswering,Yo as DebertaV2ForSequenceClassification,Ko as DebertaV2ForTokenClassification,ea as DebertaV2Model,ta as DebertaV2PreTrainedModel,sa as DebertaV2Tokenizer,xt as DeiTFeatureExtractor,oa as DeiTForImageClassification,aa as DeiTModel,na as DeiTPreTrainedModel,ia as DepthAnythingForDepthEstimation,ra as DepthAnythingPreTrainedModel,ls as DepthEstimationPipeline,At as DetrFeatureExtractor,la as DetrForObjectDetection,ca as DetrForSegmentation,da as DetrModel,ua as DetrObjectDetectionOutput,ha as DetrPreTrainedModel,fa as DetrSegmentationOutput,pa as Dinov2ForImageClassification,ma as Dinov2Model,_a as Dinov2PreTrainedModel,ga as DistilBertForMaskedLM,Ma as DistilBertForQuestionAnswering,ba as DistilBertForSequenceClassification,wa as DistilBertForTokenClassification,ya as DistilBertModel,Ta as DistilBertPreTrainedModel,xa as DistilBertTokenizer,ns as DocumentQuestionAnsweringPipeline,ye as DonutFeatureExtractor,ka as DonutSwinModel,Fa as DonutSwinPreTrainedModel,Aa as ElectraForMaskedLM,Pa as ElectraForQuestionAnswering,za as ElectraForSequenceClassification,Ca as ElectraForTokenClassification,Sa as ElectraModel,va as ElectraPreTrainedModel,Ea as ElectraTokenizer,La as EsmForMaskedLM,Ia as EsmForSequenceClassification,Ba as EsmForTokenClassification,Ra as EsmModel,Da as EsmPreTrainedModel,Oa as EsmTokenizer,ze as FFT,ja as FalconForCausalLM,qa as FalconModel,Na as FalconPreTrainedModel,Va as FalconTokenizer,Ut as FeatureExtractionPipeline,V as FeatureExtractor,Wt as FillMaskPipeline,pt as GLPNFeatureExtractor,Ga as GLPNForDepthEstimation,Xa as GLPNModel,Wa as GLPNPreTrainedModel,$a as GPT2LMHeadModel,Qa as GPT2Model,Ha as GPT2PreTrainedModel,Ua as GPT2Tokenizer,Za as GPTBigCodeForCausalLM,Ja as GPTBigCodeModel,Ya as GPTBigCodePreTrainedModel,Ka as GPTJForCausalLM,en as GPTJModel,tn as GPTJPreTrainedModel,sn as GPTNeoForCausalLM,on as GPTNeoModel,an as GPTNeoPreTrainedModel,nn as GPTNeoXForCausalLM,rn as GPTNeoXModel,ln as GPTNeoXPreTrainedModel,cn as GPTNeoXTokenizer,dn as GemmaTokenizer,un as HerbertTokenizer,hn as HubertForCTC,fn as HubertForSequenceClassification,pn as HubertModel,es as ImageClassificationPipeline,k as ImageFeatureExtractor,mn as ImageMattingOutput,ts as ImageSegmentationPipeline,rs as ImageToImagePipeline,Kt as ImageToTextPipeline,_n as LlamaForCausalLM,gn as LlamaModel,Mn as LlamaPreTrainedModel,bn as LlamaTokenizer,wn as LongT5ForConditionalGeneration,yn as LongT5Model,Tn as LongT5PreTrainedModel,xn as M2M100ForConditionalGeneration,kn as M2M100Model,Fn as M2M100PreTrainedModel,An as M2M100Tokenizer,Pn as MBart50Tokenizer,zn as MBartForCausalLM,Cn as MBartForConditionalGeneration,Sn as MBartForSequenceClassification,vn as MBartModel,En as MBartPreTrainedModel,Ln as MBartTokenizer,In as MPNetForMaskedLM,Bn as MPNetForQuestionAnswering,Rn as MPNetForSequenceClassification,Dn as MPNetForTokenClassification,On as MPNetModel,jn as MPNetPreTrainedModel,qn as MPNetTokenizer,Nn as MT5ForConditionalGeneration,Vn as MT5Model,Gn as MT5PreTrainedModel,Xn as MarianMTModel,Wn as MarianModel,$n as MarianPreTrainedModel,Qn as MarianTokenizer,Hn as MaskedLMOutput,Un as MistralForCausalLM,Zn as MistralModel,Jn as MistralPreTrainedModel,Yn as MobileBertForMaskedLM,Kn as MobileBertForQuestionAnswering,ei as MobileBertForSequenceClassification,ti as MobileBertModel,si as MobileBertPreTrainedModel,oi as MobileBertTokenizer,yt as MobileViTFeatureExtractor,ai as MobileViTForImageClassification,ni as MobileViTModel,ii as MobileViTPreTrainedModel,ri as ModelOutput,li as MptForCausalLM,ci as MptModel,di as MptPreTrainedModel,ui as NllbTokenizer,hi as NomicBertModel,fi as NomicBertPreTrainedModel,Ft as NougatImageProcessor,pi as NougatTokenizer,mi as OPTForCausalLM,_i as OPTModel,gi as OPTPreTrainedModel,os as ObjectDetectionPipeline,we as OwlViTFeatureExtractor,Mi as OwlViTForObjectDetection,bi as OwlViTModel,wi as OwlViTPreTrainedModel,Nt as OwlViTProcessor,yi as Owlv2ForObjectDetection,Tt as Owlv2ImageProcessor,Ti as Owlv2Model,xi as Owlv2PreTrainedModel,ki as PhiForCausalLM,Fi as PhiModel,Ai as PhiPreTrainedModel,A as Pipeline,Pi as PreTrainedModel,zi as PreTrainedTokenizer,Ci as PretrainedConfig,Si as PretrainedMixin,$ as Processor,vi as QuestionAnsweringModelOutput,Xt as QuestionAnsweringPipeline,Ei as Qwen2ForCausalLM,Li as Qwen2Model,Ii as Qwen2PreTrainedModel,Bi as Qwen2Tokenizer,H as RawImage,Ri as ResNetForImageClassification,Di as ResNetModel,Oi as ResNetPreTrainedModel,ji as RoFormerForMaskedLM,qi as RoFormerForQuestionAnswering,Ni as RoFormerForSequenceClassification,Vi as RoFormerForTokenClassification,Gi as RoFormerModel,Xi as RoFormerPreTrainedModel,Wi as RoFormerTokenizer,$i as RobertaForMaskedLM,Qi as RobertaForQuestionAnswering,Hi as RobertaForSequenceClassification,Ui as RobertaForTokenClassification,Zi as RobertaModel,Ji as RobertaPreTrainedModel,Yi as RobertaTokenizer,zt as SamImageProcessor,Ki as SamImageSegmentationOutput,er as SamModel,tr as SamPreTrainedModel,Dt as SamProcessor,Lt as SeamlessM4TFeatureExtractor,dt as SegformerFeatureExtractor,sr as SegformerForImageClassification,or as SegformerForSemanticSegmentation,ar as SegformerPreTrainedModel,nr as Seq2SeqLMOutput,ir as SequenceClassifierOutput,gt as SiglipImageProcessor,rr as SiglipModel,lr as SiglipPreTrainedModel,cr as SiglipTextModel,dr as SiglipTokenizer,ur as SiglipVisionModel,Rt as SpeechT5FeatureExtractor,hr as SpeechT5ForSpeechToText,fr as SpeechT5ForTextToSpeech,pr as SpeechT5HifiGan,mr as SpeechT5PreTrainedModel,qt as SpeechT5Processor,_r as SpeechT5Tokenizer,gr as SqueezeBertForMaskedLM,Mr as SqueezeBertForQuestionAnswering,br as SqueezeBertForSequenceClassification,wr as SqueezeBertModel,yr as SqueezeBertPreTrainedModel,Tr as SqueezeBertTokenizer,$t as SummarizationPipeline,xr as Swin2SRForImageSuperResolution,Ct as Swin2SRImageProcessor,kr as Swin2SRModel,Fr as Swin2SRPreTrainedModel,Ar as SwinForImageClassification,Pr as SwinModel,zr as SwinPreTrainedModel,Cr as T5ForConditionalGeneration,Sr as T5Model,vr as T5PreTrainedModel,Er as T5Tokenizer,Lr as TableTransformerForObjectDetection,Ir as TableTransformerModel,Br as TableTransformerObjectDetectionOutput,Rr as TableTransformerPreTrainedModel,z as Tensor,ce as Text2TextGenerationPipeline,Vt as TextClassificationPipeline,Qt as TextGenerationPipeline,is as TextToAudioPipeline,Gt as TokenClassificationPipeline,Dr as TokenClassifierOutput,Or as TokenizerModel,jr as TrOCRForCausalLM,qr as TrOCRPreTrainedModel,xe as TranslationPipeline,bt as ViTFeatureExtractor,Nr as ViTForImageClassification,wt as ViTImageProcessor,Vr as ViTModel,Gr as ViTPreTrainedModel,Xr as VisionEncoderDecoderModel,Wr as VitMatteForImageMatting,St as VitMatteImageProcessor,$r as VitMattePreTrainedModel,Qr as VitsModel,Hr as VitsModelOutput,Ur as VitsPreTrainedModel,Zr as VitsTokenizer,Jr as Wav2Vec2BertForCTC,Yr as Wav2Vec2BertForSequenceClassification,Kr as Wav2Vec2BertModel,el as Wav2Vec2BertPreTrainedModel,tl as Wav2Vec2CTCTokenizer,Et as Wav2Vec2FeatureExtractor,sl as Wav2Vec2ForCTC,ol as Wav2Vec2ForSequenceClassification,al as Wav2Vec2Model,nl as Wav2Vec2PreTrainedModel,jt as Wav2Vec2ProcessorWithLM,il as WavLMForCTC,rl as WavLMForSequenceClassification,ll as WavLMModel,cl as WavLMPreTrainedModel,vt as WhisperFeatureExtractor,dl as WhisperForConditionalGeneration,ul as WhisperModel,hl as WhisperPreTrainedModel,Ot as WhisperProcessor,fl as WhisperTokenizer,pl as XLMForQuestionAnswering,ml as XLMForSequenceClassification,_l as XLMForTokenClassification,gl as XLMModel,Ml as XLMPreTrainedModel,bl as XLMRobertaForMaskedLM,wl as XLMRobertaForQuestionAnswering,yl as XLMRobertaForSequenceClassification,Tl as XLMRobertaForTokenClassification,xl as XLMRobertaModel,kl as XLMRobertaPreTrainedModel,Fl as XLMRobertaTokenizer,Al as XLMTokenizer,Pl as XLMWithLMHeadModel,Pt as YolosFeatureExtractor,zl as YolosForObjectDetection,Cl as YolosModel,Sl as YolosObjectDetectionOutput,vl as YolosPreTrainedModel,Jt as ZeroShotAudioClassificationPipeline,Ht as ZeroShotClassificationPipeline,ss as ZeroShotImageClassificationPipeline,as as ZeroShotObjectDetectionPipeline,Ee as cat,El as dynamicTimeWarping,Ll as env,te as getTopItems,fe as hanning,Q as interpolate,Il as interpolate_data,Bl as log_softmax,j as max,Rl as mean,Ke as mean_pooling,Dl as medianFilter,U as mel_filter_bank,Se as min,Ol as ones,jl as ones_like,fs as pipeline,tt as read_audio,et as round,E as softmax,se as spectrogram,ie as stack,ql as std_mean,ve as transpose,Nl as transpose_data,oe as window_function};
